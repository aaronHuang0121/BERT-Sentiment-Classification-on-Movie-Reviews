{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/biolab/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/biolab/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/biolab/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41411</td>\n",
       "      <td>I watched this film because I'm a big fan of R...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37586</td>\n",
       "      <td>It does not seem that this movie managed to pl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6017</td>\n",
       "      <td>Enough is not a bad movie , just mediocre .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44656</td>\n",
       "      <td>my friend and i rented this one a few nights a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38711</td>\n",
       "      <td>Just about everything in this movie is wrong, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                             review  sentiment\n",
       "0  41411  I watched this film because I'm a big fan of R...          0\n",
       "1  37586  It does not seem that this movie managed to pl...          1\n",
       "2   6017        Enough is not a bad movie , just mediocre .          0\n",
       "3  44656  my friend and i rented this one a few nights a...          0\n",
       "4  38711  Just about everything in this movie is wrong, ...          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = pd.read_csv('../data/train.csv', header=0)\n",
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22622</td>\n",
       "      <td>Robert Lansing plays a scientist experimenting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10162</td>\n",
       "      <td>Well I've enjoy this movie, even though someti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17468</td>\n",
       "      <td>First things first - though I believe Joel Sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42579</td>\n",
       "      <td>I watched this movie on the grounds that Amber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>701</td>\n",
       "      <td>A certain sexiness underlines even the dullest...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                             review\n",
       "0  22622  Robert Lansing plays a scientist experimenting...\n",
       "1  10162  Well I've enjoy this movie, even though someti...\n",
       "2  17468  First things first - though I believe Joel Sch...\n",
       "3  42579  I watched this movie on the grounds that Amber...\n",
       "4    701  A certain sexiness underlines even the dullest..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_dataset = pd.read_csv('../data/test.csv',  header=0)\n",
    "predict_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/home/biolab/.cache/huggingface/datasets/imdb/plain_text/1.0.0/90099cb476936b753383ba2ae6ab2eae419b2e87f71cd5189cb9c8e5814d12a3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_datasets = load_dataset(\"imdb\")\n",
    "imdb_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除字尾\n",
    "def StemProcess(word):\n",
    "    lemma = lemmatizer.lemmatize(word, 'v')\n",
    "    if lemma == word:\n",
    "        lemma = lemmatizer.lemmatize(word, 'n')\n",
    "    if lemma == word:\n",
    "        lemma = lemmatizer.lemmatize(word, 'a')\n",
    "    if lemma == word:\n",
    "        lemma = lemmatizer.lemmatize(word, 'r')\n",
    "    return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removePunctuation(sentence):\n",
    "    return ' '.join(list(filter(lambda word: word not in string.punctuation, sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractPartial(text):\n",
    "    text = bs(text, 'html.parser').text\n",
    "#     text = re.findall(r\"[\\w']+|[.,!?;]\", text)\n",
    "#     text = sent_tokenize(text)\n",
    "#     text = list(map(lambda word: StemProcess(word), text))\n",
    "#     text = list(filter(lambda word: word not in stopwords.words('english'), text))\n",
    "#     text = list(map(lambda sentence: re.findall(r\"[\\w']+|[.,!?;]\", sentence), text))\n",
    "#     text = list(map(lambda sentence: removePunctuation(sentence), text))\n",
    "#     text = ' [SEP] '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processReviews(texts):\n",
    "    results = []\n",
    "    count = 0\n",
    "    for text in texts:\n",
    "        count += len(text)\n",
    "        results += list(map(lambda x: extractPartial(x), text))\n",
    "        print(\"Finish {count} texts...\".format(count=count))\n",
    "    max_len = len(max(results, key=len))\n",
    "    print(\"dataset review shape = ({0}, {1})\".format(len(results), max_len))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 1000 texts...\n",
      "Finish 2000 texts...\n",
      "Finish 3000 texts...\n",
      "Finish 4000 texts...\n",
      "Finish 5000 texts...\n",
      "Finish 6000 texts...\n",
      "Finish 7000 texts...\n",
      "Finish 8000 texts...\n",
      "Finish 9000 texts...\n",
      "Finish 10000 texts...\n",
      "Finish 11000 texts...\n",
      "Finish 12000 texts...\n",
      "Finish 13000 texts...\n",
      "Finish 14000 texts...\n",
      "Finish 15000 texts...\n",
      "Finish 16000 texts...\n",
      "Finish 17000 texts...\n",
      "Finish 18000 texts...\n",
      "Finish 19000 texts...\n",
      "Finish 20000 texts...\n",
      "Finish 21000 texts...\n",
      "Finish 22000 texts...\n",
      "Finish 23000 texts...\n",
      "Finish 24000 texts...\n",
      "Finish 25000 texts...\n",
      "Finish 26000 texts...\n",
      "Finish 27000 texts...\n",
      "Finish 28000 texts...\n",
      "Finish 29000 texts...\n",
      "Finish 29341 texts...\n",
      "dataset review shape = (29341, 12804)\n"
     ]
    }
   ],
   "source": [
    "train_texts = [train_dataset['review'][i: i+N] for i in range(0, len(train_dataset['review']), N)]\n",
    "train_results = processReviews(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/sentiments_beautify_html.json', 'w') as file:\n",
    "    json.dump(train_results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For predict dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 1000 texts...\n",
      "Finish 2000 texts...\n",
      "Finish 3000 texts...\n",
      "Finish 4000 texts...\n",
      "Finish 5000 texts...\n",
      "Finish 6000 texts...\n",
      "Finish 7000 texts...\n",
      "Finish 8000 texts...\n",
      "Finish 9000 texts...\n",
      "Finish 10000 texts...\n",
      "Finish 11000 texts...\n",
      "Finish 12000 texts...\n",
      "Finish 13000 texts...\n",
      "Finish 14000 texts...\n",
      "Finish 15000 texts...\n",
      "Finish 16000 texts...\n",
      "Finish 17000 texts...\n",
      "Finish 18000 texts...\n",
      "Finish 19000 texts...\n",
      "Finish 20000 texts...\n",
      "Finish 21000 texts...\n",
      "Finish 22000 texts...\n",
      "Finish 23000 texts...\n",
      "Finish 24000 texts...\n",
      "Finish 25000 texts...\n",
      "Finish 26000 texts...\n",
      "Finish 27000 texts...\n",
      "Finish 28000 texts...\n",
      "Finish 29000 texts...\n",
      "Finish 29341 texts...\n",
      "dataset review shape = (29341, 14212)\n"
     ]
    }
   ],
   "source": [
    "predict_texts = [predict_dataset['review'][i: i+N] for i in range(0, len(predict_dataset['review']), N)]\n",
    "predict_results = processReviews(predict_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/predicts_beautify_html.json', 'w') as file:\n",
    "    json.dump(predict_results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For IMDB datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 1000 texts...\n",
      "Finish 2000 texts...\n",
      "Finish 3000 texts...\n",
      "Finish 4000 texts...\n",
      "Finish 5000 texts...\n",
      "Finish 6000 texts...\n",
      "Finish 7000 texts...\n",
      "Finish 8000 texts...\n",
      "Finish 9000 texts...\n",
      "Finish 10000 texts...\n",
      "Finish 11000 texts...\n",
      "Finish 12000 texts...\n",
      "Finish 13000 texts...\n",
      "Finish 14000 texts...\n",
      "Finish 15000 texts...\n",
      "Finish 16000 texts...\n",
      "Finish 17000 texts...\n",
      "Finish 18000 texts...\n",
      "Finish 19000 texts...\n",
      "Finish 20000 texts...\n",
      "Finish 21000 texts...\n",
      "Finish 22000 texts...\n",
      "Finish 23000 texts...\n",
      "Finish 24000 texts...\n",
      "Finish 25000 texts...\n",
      "dataset review shape = (25000, 13584)\n"
     ]
    }
   ],
   "source": [
    "imdb_train_texts = [imdb_datasets['train']['text'][i: i+N] for i in range(0, len(imdb_datasets['train']['text']), N)]\n",
    "imdb_train_results = processReviews(imdb_train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 1000 texts...\n",
      "Finish 2000 texts...\n",
      "Finish 3000 texts...\n",
      "Finish 4000 texts...\n",
      "Finish 5000 texts...\n",
      "Finish 6000 texts...\n",
      "Finish 7000 texts...\n",
      "Finish 8000 texts...\n",
      "Finish 9000 texts...\n",
      "Finish 10000 texts...\n",
      "Finish 11000 texts...\n",
      "Finish 12000 texts...\n",
      "Finish 13000 texts...\n",
      "Finish 14000 texts...\n",
      "Finish 15000 texts...\n",
      "Finish 16000 texts...\n",
      "Finish 17000 texts...\n",
      "Finish 18000 texts...\n",
      "Finish 19000 texts...\n",
      "Finish 20000 texts...\n",
      "Finish 21000 texts...\n",
      "Finish 22000 texts...\n",
      "Finish 23000 texts...\n",
      "Finish 24000 texts...\n",
      "Finish 25000 texts...\n",
      "dataset review shape = (25000, 12690)\n"
     ]
    }
   ],
   "source": [
    "imdb_test_texts = [imdb_datasets['test']['text'][i: i+N] for i in range(0, len(imdb_datasets['test']['text']), N)]\n",
    "imdb_test_results = processReviews(imdb_test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/imdb_train_beautify_html.json', 'w') as file:\n",
    "    json.dump(imdb_train_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/imdb_test_beautify_html.json', 'w') as file:\n",
    "    json.dump(imdb_test_results, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Aaron_env",
   "language": "python",
   "name": "aaron_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
